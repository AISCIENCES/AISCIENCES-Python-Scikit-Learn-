{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1. Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset using fetch_openml function\n",
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the shape of the dataset\n",
    "print(mnist.data.shape)\n",
    "\n",
    "#printing unique labels in the dataset\n",
    "import numpy as np\n",
    "np.unique(mnist.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#printing the first image\n",
    "image_0 = mnist.data[0].reshape(28,28)\n",
    "import matplotlib.pyplot as plt \n",
    "plt.gray() \n",
    "plt.matshow(image_0) \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#printing the label for the first image\n",
    "label_0 = mnist.target[0]\n",
    "print(label_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2. Dividing the dataset into Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating feature set\n",
    "X = mnist.data\n",
    "\n",
    "#creating label set\n",
    "y = mnist.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3. Divide Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dividing data into the training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.4. Data Scaling/Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying standard scaling to the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform (X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.5. Training and Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing random forest classifier from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_estimators=500)\n",
    "\n",
    "#training the random forest classifier\n",
    "classifier = rf_clf.fit(X_train, y_train)\n",
    "\n",
    "#making predictions on the test set\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.6. Evaluating the Algorithm on Test Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1367    0    1    0    2    4    7    0    6    0]\n",
      " [   0 1560    6    4    3    0    2    2    2    1]\n",
      " [   2    2 1409    5    3    1    5    8    7    1]\n",
      " [   1    1   23 1364    0   15    0   11   14    6]\n",
      " [   3    0    0    0 1314    0    4    5    3   21]\n",
      " [   1    3    4    9    1 1185   12    1    9    6]\n",
      " [   5    2    1    0    4    7 1364    0    4    0]\n",
      " [   3    5   20    1    9    0    0 1399    2   19]\n",
      " [   0    9    5    5    4    4    3    0 1318   20]\n",
      " [   4    2    3   18   12    5    2   13    8 1294]]\n",
      "0.9695714285714285\n"
     ]
    }
   ],
   "source": [
    "#evaluating the algorithm on test set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11.1\n",
    "\n",
    "\n",
    "### Question 1:\n",
    "\n",
    "A colored image has __ channels:\n",
    "\n",
    "A- 1 \\\n",
    "B- 2 \\\n",
    "C- 3 \\\n",
    "D- 4 \n",
    "\n",
    "Answer: C\n",
    "    \n",
    "    \n",
    "### Question 2:\n",
    "\n",
    "You need to convert an image into a ___ dimensional array before you can use Scikit-learn to train models on image data?\n",
    "\n",
    "A- 1 \\\n",
    "B- 2 \\\n",
    "C- 3 \\\n",
    "D- 4\n",
    "\n",
    "Answer: A\n",
    "\n",
    "\n",
    "### Question 3:\n",
    "\n",
    "To convert a one dimensional numpy array into a two-dimensional array or matrix, which method can be used??\n",
    "\n",
    "A- np.tomatrix() \\\n",
    "B- pd.convert2d \\\n",
    "C- pd.reshape() \\\n",
    "D- None of the above\n",
    "\n",
    "Answer: C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11.2\n",
    "Divide the following image dataset into 80% training and 20% test sets. Train the model on the training set and make predictions on the test set. Print the accuracy and confusion matrix for the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset using fetch_openml function\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "n_samples = len(digits.images)\n",
    "X = digits.images.reshape((n_samples, -1))\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[27  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 35  0  0  0  0  0  0  0  0]\n",
      " [ 1  1 34  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 29  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 29  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 39  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 44  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 39  0  0]\n",
      " [ 0  1  0  1  0  0  0  1 36  0]\n",
      " [ 0  0  0  0  0  1  0  0  0 40]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        27\n",
      "           1       0.95      1.00      0.97        35\n",
      "           2       1.00      0.94      0.97        36\n",
      "           3       0.97      1.00      0.98        29\n",
      "           4       1.00      0.97      0.98        30\n",
      "           5       0.97      0.97      0.97        40\n",
      "           6       1.00      1.00      1.00        44\n",
      "           7       0.95      1.00      0.97        39\n",
      "           8       1.00      0.92      0.96        39\n",
      "           9       0.98      0.98      0.98        41\n",
      "\n",
      "    accuracy                           0.98       360\n",
      "   macro avg       0.98      0.98      0.98       360\n",
      "weighted avg       0.98      0.98      0.98       360\n",
      "\n",
      "0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "#dividing data into the training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size=0.20, random_state=0)\n",
    "\n",
    "#applying standard scaling to the dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform (X_test)\n",
    "\n",
    "#importing random forest classifier from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_estimators=500)\n",
    "\n",
    "#training the random forest classifier\n",
    "classifier = rf_clf.fit(X_train, y_train)\n",
    "\n",
    "#making predictions on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#evaluating the algorithm on test set\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
